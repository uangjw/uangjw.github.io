<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.2">Jekyll</generator><link href="https://uangjw.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://uangjw.github.io/" rel="alternate" type="text/html" /><updated>2022-04-20T13:18:09+00:00</updated><id>https://uangjw.github.io/feed.xml</id><title type="html">Bird Nest</title><subtitle>-</subtitle><author><name>Jingwen Huang</name></author><entry><title type="html"></title><link href="https://uangjw.github.io/2022/04/20/2022-02-21-paper-music-transformer/" rel="alternate" type="text/html" title="" /><published>2022-04-20T13:18:09+00:00</published><updated>2022-04-20T13:18:09+00:00</updated><id>https://uangjw.github.io/2022/04/20/2022-02-21-paper-music-transformer</id><content type="html" xml:base="https://uangjw.github.io/2022/04/20/2022-02-21-paper-music-transformer/">&lt;h3 id=&quot;music-transformer&quot;&gt;Music Transformer&lt;/h3&gt;

&lt;p&gt;Music Transformer是一个基于Transformer的音乐生成模型。面对自动音乐生成的问题，Music Transformer在原模型的基础上改进了其所使用的注意力机制；Transformer完全使用注意力层以及全连接层的模型结构可能忽略信号的相对关系特征，Music Transformer在Transformer的基础上使用relative attention，这种注意力机制显式地根据两个标记之间的距离估计注意力分数，从而能够关注在音乐序列中具有更明显作用的相对关系特征。&lt;/p&gt;

&lt;h4 id=&quot;relative-positional-self-attention&quot;&gt;relative positional self-attention&lt;/h4&gt;

&lt;p&gt;文章Self-Attention with Relative Position Representations首先改进Transformer的注意力机制为relative self-attention。该文指出，Transformer与RNN、CNN不同，不对输入序列的相对或绝对位置信息显式地建模，因此只能把绝对位置的表示也作为输入（即位置编码）来让模型考虑。relative self-attention机制能够有效地考虑相对位置的表示，或者说序列元素之间的距离，从而在进行注意力打分时能够高效地提取出序列基于标记间相对位置的特征。Music Transformer所使用的relative self-attention算法是前述文章的算法的改进版，主要减少了空间复杂度。&lt;/p&gt;

&lt;p&gt;Transformer的文章中3.5节就描述了其中使用的位置编码（positional encoding）。在编码器和解码器的输入前，需要给输入的词嵌入向量加上位置编码，从而使得模型能够在学习中利用序列的顺序信息。具体来说，文章提出的模型使用了如下两个函数来保证模型能够轻松地从相对位置信息中学习：
\(PE_{(pos, 2i)}=sin(pos/10000^{2i/d_{model}}) \\
PE_{(pos, 2i+1)}=cos(pos/10000^{2i/d_{model}})\)
其中$pos$是token的位置索引，$i$是维度。也就是说，位置编码的每一个维度都是个正弦信号。需要注意到的是，针对任意的偏移常量$k$，都可以用$PE_{pos}$的线性函数表达出$PE_{pos+k}$。&lt;/p&gt;

&lt;p&gt;Music Transformer中的注意力机制能够关注到一个序列中两个位置之间相距有多远。注意力层所学习的嵌入$E^r$具有形状$(H,L,D_h)$，其中$H$为多头注意力机制的“头数”，$L$为序列长度，$D_h$为维度。$E^r$中包含的嵌入是，对任意一对位置$i_q,j_k$的相对距离$r=j_k-i_q$，从$i_q$的一个查询向量到$j_k$的一个键向量的嵌入。这些嵌入根据相对距离大小，从$-L+1$排列到0，并且分散地被每一个注意力头所学习。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;深度学习中embedding“嵌入”到底指什么？NLP中模型的输入是word embedding词嵌入。词嵌入是一种词的类型表示，具有相似意义的词具有相似的表示，是将词汇映射到实数向量的方法总称。词嵌入技术的根本目的是为了方便机器计算。一种非常重要的词嵌入技术是Word2Vec，它是一种用于有效学习从文本语料库嵌入的独立词语的统计方法；核心思想是基于上下文，先用向量代表各个词，然后通过一个预测目标函数学习这些向量的参数。在此技术之后，“似乎一切东西都可以被embedding”。总体来说，embedding一词现在已经指代着这样的技术：构建一个映射将一个空间里的实体抛射到一个线性向量空间里去，这样一来可以在向量空间里计算度量它们的距离，亦或者从这个空间寻找到另一个目标空间的映射关系。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;self-attention-in-transformer&quot;&gt;self-attention in Transformer&lt;/h4&gt;

&lt;p&gt;在此先简要总结Transformer中的自注意力机制scaled dot-product attention。&lt;/p&gt;

&lt;p&gt;注意力层的输入是$L$个$D$维的向量的集合$X=(x_1,x_2,…,x_L)$。$Q$是查询张量，通过$X$与$D\times D$的权值矩阵$W^Q$相乘得到；键值向量$K$与$V$同理，$KQV$的形状都是$L\times D$。多头注意力机制就是划分前述$KQV$为$H$个$L\times D_h$的张量，$h$为注意力头的索引，维数$D_h=\frac{D}{H}$。“多头”的设计让模型能够关注一个历史token的不同部分。最后注意力打分的计算公式为：
\(Z^h=Attention(Q^h,K^h,V^h)=Softmax(\frac{Q^hK^{h\top}}{\sqrt{D_h}})V^h\)&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;images/transformer4.png&quot; div=&quot;&quot; align=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;relative-positional-self-attention-1&quot;&gt;relative positional self-attention&lt;/h4&gt;

&lt;p&gt;文章Self-Attention with Relative Position Representations的注意力机制能够关注到一个序列中两个位置之间相距有多远。注意力层所学习的嵌入$E^r$具有形状$(H,L,D_h)$，其中$H$为多头注意力机制的“头数”，$L$为序列长度，$D_h$为维度。$E^r$中包含的嵌入是，对任意一对位置$i_q,j_k$的相对距离$r=j_k-i_q$，从$i_q$的一个查询向量到$j_k$的一个键向量的嵌入$e_{ij}$。&lt;/p&gt;

&lt;p&gt;要理解$e_{ij}$怎么来的，还是需要参考文章Self-Attention with Relative Position Representations的描述。首先这种注意力机制将输入序列建模成一个有向全连接图，两个序列元素间的边用键值向量$a^K_{ij}$与$a^V_{ij}$表示。$a^K_{ij}$用于计算scaled dot-product，即$x_i$到$x_j$的权重系数$e_{ij}$：
\(e_{ij}=\frac{Q(K+a^K_{ij})\top}{\sqrt{D_h}}\)
这些嵌入根据相对距离大小，从$-L+1$排列到0，并且分散地被每一个注意力头所学习。$E^r$与查询向量经过一点计算，最后就得到一个$L\times L$的对数矩阵$S^{rel}$。这样，每个“头”的注意力分数就通过下式计算得到（公式中省去了注意力头的索引$h$）：
\(RelativeAttention = Softmax(\frac{QK^{\top}+S^{rel}}{\sqrt{D_h}})V\)
Music Transformer使用了相同的方法来在注意力打分过程中引入相对位置信息的影响。Music Transformer优化了$S^{rel}$的计算方法，从而降低了这种注意力机制的空间复杂度。&lt;/p&gt;

&lt;p&gt;RPR self-attention的原文章中，从$E^r$每一个注意力头的分量到对应的$S^{rel}$的计算过程包括计算一个$(L,L,D_h)$形状的中间张量$R$，$R$包括了与所有键值之间的相对距离相关联的嵌入（也就是前面的$a^K_{ij}$）。$S^{rel}$的计算是将$L\times D_h$的$Q$拉成$(L,1,D_h)$后与$R$相乘得来的，即$S^{rel}=QR^{\top}$。$R$的存在将算法的空间复杂度拉到了$O(L^2D)$，从而限制了它在长序列中的应用。&lt;/p&gt;

&lt;p&gt;Music Transformer中的RPR self-attention做出了这样的改进：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;images/musictransformer.png&quot; div=&quot;&quot; align=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;也即，把从$E^r$得到$S^{rel}$的计算过程中对$R$的需求转化成了四个操作，这四个操作的具体效果图片已经展示得很清晰了。&lt;/p&gt;</content><author><name>Jingwen Huang</name></author></entry><entry><title type="html">论文笔记||Attention Is All You Need</title><link href="https://uangjw.github.io/2022/02/07/paper-transformer/" rel="alternate" type="text/html" title="论文笔记||Attention Is All You Need" /><published>2022-02-07T00:00:00+00:00</published><updated>2022-02-07T00:00:00+00:00</updated><id>https://uangjw.github.io/2022/02/07/paper-transformer</id><content type="html" xml:base="https://uangjw.github.io/2022/02/07/paper-transformer/">&lt;h3 id=&quot;transformer&quot;&gt;Transformer&lt;/h3&gt;

&lt;p&gt;Music Transformer的模型建立在Transformer模型的基础之上。&lt;/p&gt;

&lt;p&gt;论文：Attention Is All You Need&lt;/p&gt;

&lt;p&gt;参考博客：https://blog.csdn.net/longxinchen_ml/article/details/86533005&lt;/p&gt;

&lt;p&gt;Transformer模型首次于文章Attention Is All You Need提出，如题目所述，模型仅仅依赖注意力机制来表达输入输出之间的全局依赖，完全摒弃了循环与卷积。相对于具有相同性能的其他模型，Transformer更可并行化，且需求的训练时间更短。&lt;/p&gt;

&lt;h4 id=&quot;模型架构&quot;&gt;模型架构&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;/images/transformer1.png&quot; style=&quot;zoom: 80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;编码器：6个相同的网络层组成，其中每层都有两个子网络层（或者理解成6个编码器级联）。子层中按传输顺序第一个是一个Multi-Head self-attention机制，即一个自注意力层。第二个子层是一个简单的全连接前馈网络层。&lt;/p&gt;

&lt;p&gt;解码器：同样由6个相同的网络层组成，除了与编码器相同的两个子层，解码器中还有一个对编码器的输出执行multi-head attention的子层。&lt;/p&gt;

&lt;p&gt;编码器与解码器的层与层之间都采用残差连接，并对每层输出进行归一化（这两步即图中Add&amp;amp;Norm，将层输出与输入相加并归一化，目的是应对梯度消失以及防止过拟合）&lt;/p&gt;

&lt;h4 id=&quot;自注意力机制&quot;&gt;自注意力机制&lt;/h4&gt;

&lt;p&gt;注意力函数（attention function）可以看作是一个从一个查询与一组键值对到一个输出的映射，其中查询、键、值以及输出都是向量，它们的创建都是通过一个权值矩阵与待处理的向量相乘实现的。在NLP情形下，可以认为自注意力机制就是在模型处理输入序列的每个单词时能够关注到整个序列中的所有单词，从而更好地编/解码；具体来说，当我们希望查询某单词在句子的其他位置上的“注意力”，我们就将其他位置上的单词拿来对该单词做“注意力计算（打分）”，计算结果决定了编码该单词的过程中有多重视句子的其它部分。&lt;/p&gt;

&lt;p&gt;作者使用的Scaled Dot-Product Attention机制的结构如下图。计算相应的attention值的流程可以表达为如下公式：
\(Attention(Q,K,V)=softmax(\frac{QK^T}{\sqrt{d_k}})V\)
其中$Q$即请求向量，$K$即所有键值组成的向量，$V$即所有键对应值的向量，$d_k$即键值对的维数。这种计算attention的方式是在一般的dot-product attention的基础上多除了一个维数的平方根，这一步可以让梯度更稳定。将注意力分数计算完毕后通过softmax函数来传递结果，这一步使得所有单词的分数都归一化，得到的分数都是正值且和为1。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/transformer3.png&quot; style=&quot;zoom: 80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;前面描述模型结构的时候提到实际上用到的是Multi-Head Attention机制（多头注意力机制）。多头注意力机制扩展了模型专注于输入序列不同位置的能力，给出了注意力层的多个“表示子空间”（论文的表述：“能够联合地从不同的表示子空间中关注不同位置的信息”）。结合下图理解多头注意力机制，向量VKQ并行地进行h次线性投影（linear projection，通过矩阵乘法进行），投影结果将被并行地进行scaled dot-product注意力分数计算，然后拼接到一起再被线性投影，得到一个矩阵。公式表达为：
\(MultiHead(Q,K,V)=Concat(head_1,...,head_h)W^O \\
where \ head_i=Attention(QW_i^Q,KW_I^K,VW_i^V)\)
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/transformer2.png&quot; style=&quot;zoom: 80%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/transformer4.png&quot; div=&quot;&quot; align=&quot;center&quot; /&gt;&lt;/p&gt;</content><author><name>Jingwen Huang</name></author><category term="PaperNotes" /><category term="Deep Learning" /><summary type="html">Transformer</summary></entry><entry><title type="html">论文笔记||Sketch Generation with Drawing Process Guided by Vector Flow and Grayscale</title><link href="https://uangjw.github.io/2021/11/12/paper-sktech-generation/" rel="alternate" type="text/html" title="论文笔记||Sketch Generation with Drawing Process Guided by Vector Flow and Grayscale" /><published>2021-11-12T00:00:00+00:00</published><updated>2021-11-12T00:00:00+00:00</updated><id>https://uangjw.github.io/2021/11/12/paper-sktech-generation</id><content type="html" xml:base="https://uangjw.github.io/2021/11/12/paper-sktech-generation/">&lt;h3 id=&quot;生成笔触绘画过程&quot;&gt;生成笔触绘画过程：&lt;/h3&gt;

&lt;h4 id=&quot;grayscale-guidance&quot;&gt;Grayscale Guidance&lt;/h4&gt;

&lt;p&gt;首先调整输入灰度图像的直方图，改善其色调hue；使用CLAHE加强输入图像的对比度&lt;/p&gt;

&lt;p&gt;接着对输入图像的灰度量化为${G_1,G_2,…,G_n}$，由此步骤新生成的图像记为$Q$&lt;/p&gt;

&lt;p&gt;按行扫描Q，每一行中具有小于等于灰度级G的灰度的像素被视为一个区间，这一区间的开始像素就是未来笔触的开始位置，灰度级G即为这一笔触的central pixel gray value mean；这样就可以把水平方向的笔触画出来了（笔触的宽度W是提前确定的，是一个用户可调节的参数）&lt;/p&gt;

&lt;p&gt;利用这种方法，可以通过旋转Q来画出各个方向的笔触&lt;/p&gt;

&lt;h4 id=&quot;direction-guidance&quot;&gt;Direction Guidance&lt;/h4&gt;

&lt;p&gt;观察真实素描画可以看出，笔触的方向通常是沿着边缘的切线的&lt;/p&gt;

&lt;p&gt;使用输入图像的梯度信息来做这个笔触方向的预测，因为梯度与边缘通常是紧密联系的。&lt;/p&gt;

&lt;p&gt;使用ETF（edge tangent flow）来逐像素地估计笔触的方向。构造ETF的方法：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;计算每个像素的梯度向量的模和方向&lt;/li&gt;
  &lt;li&gt;将这些向量逆时针旋转90°&lt;/li&gt;
  &lt;li&gt;迭代地调整这些向量的方向，主要目的是让模长较小的向量的方向能够趋向模长较大的向量，即起到一个类似平滑的效果&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这样，各向量的方向就近似地与边缘平行了，我们得到了一个这些向量构成的分辨率与原图像相同的向量场。&lt;/p&gt;

&lt;p&gt;接下来，将输入图像根据ETF划分为一定的区域。流程：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;将向量的方向从0到2pi量化到n个值，相位差为pi的两个向量被认为具有同一方向&lt;/li&gt;
  &lt;li&gt;将具有同一方向的向量对应的像素划分到一个区域&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;分别在每个区域中绘制这一区域对应方向的笔触，就可以得到n个绘制结果，表示为${\beta_1, \beta_2, …, \beta_n}$。下一步就要将它们合并，得到整体的结果。&lt;/p&gt;

&lt;h4 id=&quot;area-merging-and-detail-enhancement&quot;&gt;Area Merging and Detail Enhancement&lt;/h4&gt;

&lt;p&gt;按笔触方向划分区域并分别进行绘制，会导致分区之间在相加后不能很好地融合到一起，且细小的分区中笔触也会很短小，整体看去就像噪声一样。文章解决这一问题的做法是将笔触的首尾延长2W个像素，W为笔触的宽度。&lt;/p&gt;

&lt;p&gt;从分区结果得到最终结果的表达式：&lt;/p&gt;

&lt;p&gt;$A=minimum(\beta_1, \beta_2, …, \beta_n)$&lt;/p&gt;

&lt;p&gt;延长笔触之后细节的清晰度受到了影响。文章的做法是用线性卷积的方法计算edge map，然后将edge map与A相乘来得到加强细节的结果。&lt;/p&gt;

&lt;h4 id=&quot;process-reconstruction&quot;&gt;Process Reconstruction&lt;/h4&gt;

&lt;p&gt;为了生成更真实的绘画过程，作者将每一个笔触按$S$排序，$S$是作者设计的能够近似地表明笔触多大程度上是细节或轮廓的描绘的参数。实际实现中，作者用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;importance&lt;/code&gt;作为变量名。在生成绘制过程之前，先将所有笔触按$S$从大到小排序，然后按顺序将它们绘制到画布上即可。&lt;/p&gt;

&lt;p&gt;$S=(255-G)\times \sum_{i\in D}T_i$&lt;/p&gt;

&lt;h3 id=&quot;改进尝试&quot;&gt;改进尝试&lt;/h3&gt;

&lt;h4 id=&quot;area-merging&quot;&gt;Area Merging&lt;/h4&gt;

&lt;p&gt;为了解决按方向划分的区域之间不能很好衔接的问题，作者直接将每个笔触延长2W个像素，这样使得结果中细节丢失很严重。作者想通过乘上一个edge map来解决这个问题，但这样并不能弥补高光之类的具有大灰度值的细节丢失。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/image-20211110210919830.png&quot; div=&quot;&quot; align=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我将延长笔触的部分改为：&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;extend_len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stroke_temp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'grayscale'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;period&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;period&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extend_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extend_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;即深色部分的笔触延长较短长度，浅色部分的笔触延长较长长度。&lt;/p&gt;

&lt;p&gt;改进并不明显……（未加edge图）&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/image-20211111003227879.png&quot; alt=&quot;image-20211111003227879&quot; style=&quot;zoom: 33%;&quot; /&gt;  &lt;img src=&quot;/images/image-20211111004120087.png&quot; alt=&quot;image-20211111004120087&quot; style=&quot;zoom: 33%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;眼睛的细节看起来保持得稍好一些，主要是像眼白这样小块的浅色区域，没有因为笔触的过分延长而变得太深&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/image-20211111004358482.png&quot; alt=&quot;image-20211111004358482&quot; style=&quot;zoom: 25%;&quot; /&gt;     &lt;img src=&quot;/images/image-20211111004429733.png&quot; alt=&quot;image-20211111004429733&quot; style=&quot;zoom: 25%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;对于非真实感渲染的效果改进往往是建立在非常主观的感受之上的。&lt;/p&gt;

&lt;p&gt;我希望能找到一个保持高光的改进方法，找不到算了&lt;/p&gt;</content><author><name>Jingwen Huang</name></author><category term="PaperNotes" /><summary type="html">生成笔触绘画过程：</summary></entry><entry><title type="html">不基于模型的预测与控制</title><link href="https://uangjw.github.io/2021/10/24/RL-model-free-control/" rel="alternate" type="text/html" title="不基于模型的预测与控制" /><published>2021-10-24T00:00:00+00:00</published><updated>2021-10-24T00:00:00+00:00</updated><id>https://uangjw.github.io/2021/10/24/RL-model-free-control</id><content type="html" xml:base="https://uangjw.github.io/2021/10/24/RL-model-free-control/">&lt;p&gt;主要参考陈旭老师的ppt以及知乎专栏https://www.zhihu.com/column/reinforce&lt;/p&gt;

&lt;p&gt;MDP未知具体来说就是$R(s,a)$与$P(s’$|$s,a)$是未知的；在现实生活中，MDP模型要么是未知的，要么是已知但实在是太大太复杂了。所以不基于模型的预测与控制方法是必要的。&lt;/p&gt;

&lt;p&gt;Model-free RL是通过与环境交互来学习的。在这里需要引入一个episode（又称trajectory，老师称之为“轨迹”）的概念，episode是agent通过与环境交互得到的一个集合，其内容可以表示为&lt;/p&gt;

&lt;p&gt;${S_1, A_1, R_1, S_2, A_2, R_2, … S_T, A_T, R_T}$&lt;/p&gt;

&lt;h3 id=&quot;model-free-prediction&quot;&gt;Model-free Prediction&lt;/h3&gt;

&lt;p&gt;这里不基于模型的预测指在一个未知的MDP上估计一个policy的价值。课堂介绍了两种方法：&lt;/p&gt;

&lt;h4 id=&quot;monte-carlo-policy-evaluation&quot;&gt;Monte Carlo policy evaluation&lt;/h4&gt;

&lt;p&gt;蒙特卡洛策略评估的目标是，在给定的policy下，从一系列完整的episode中学习得到该policy下的状态价值函数。其特点是使用有限的完整episode产生的经验性信息推导出每个状态的平均收获，以此来替代收获的期望即状态价值。&lt;/p&gt;

&lt;p&gt;基于特定policy $\pi$的一个episode信息可以表示为如下的序列&lt;/p&gt;

&lt;p&gt;${S_1, A_1, R_2, S_2, A_2, R_3, …, S_t, A_t, R_{t+1},…,S_k}$ ~ $\pi$&lt;/p&gt;

&lt;p&gt;注意这里$R$的下标与前面介绍episode的下标不一样，这里$R_{t+1}$表示的是$t$时刻个体在状态$S_t$获得的即时奖励。更准确地说是个体在状态$S_t$执行一个行为$a$后离开该状态获得的即时奖励。&lt;/p&gt;

&lt;p&gt;$t$时刻状态$S_t$的收获：&lt;/p&gt;

&lt;p&gt;$G_t=R_{t+1}+\gamma R_{t+2}+…+\gamma^{T-1}R_T$&lt;/p&gt;

&lt;p&gt;其中$T$为终止时刻。于是该policy下某一状态$s$的价值就可表示为&lt;/p&gt;

&lt;p&gt;$v_{\pi}(s)=E_{\pi}[G_t$|$S_t=s]$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Incremental MC Updates&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在状态转移过程中，可能发生一个状态经过一定的转移后又一次或多次返回该状态。一个在实际操作中常用的方法就是把Incremental Mean方法应用于蒙特卡洛策略评估，得到蒙特卡洛累进更新方法。&lt;/p&gt;

&lt;p&gt;对于一系列episode中的每一个episode，对这个episode里的每一个状态$S_t$，有一个收获$G_t$，每碰到一次$S_t$，使用下式计算状态的平均价值$V(S_t)$：&lt;/p&gt;

&lt;p&gt;$V(S_t)\leftarrow V(S_t)+\frac{1}{N(S_t)}(G_t-V(S_t))$&lt;/p&gt;

&lt;p&gt;其中$N(S_t)$就是遇到这个状态的次数，整个episode信息分析完毕后$V(S_t)$就是所有$S_t$的收获的平均值。在处理非静态问题时，使用这个方法跟踪一个实时更新的平均值是非常有用的，可以扔掉那些已经计算过的episode信息。此时可以引入参数$\alpha$来更新状态价值：&lt;/p&gt;

&lt;p&gt;$V(S_t)\leftarrow V(S_t)+\alpha(G_t-V(S_t))$&lt;/p&gt;

&lt;h4 id=&quot;temporal-difference-td-learning&quot;&gt;Temporal Difference (TD) learning&lt;/h4&gt;

&lt;p&gt;MC方法其实有很多缺点，实际应用并不多；时序差分（TD）学习方法才是实际常用的。TD学习也从episode学习，但它可以学习不完整的episode，通过自身的bootstrap来猜测episode的结果，同时持续更新这个猜测。&lt;/p&gt;

&lt;p&gt;TD学习中算法在估计某一个状态的价值时，用的是离开该状态的即刻奖励$R_{t+1}$与下一状态$S_{t+1}$的预估状态价值乘以衰减系数$\gamma$组成，符合Bellman方程的描述：&lt;/p&gt;

&lt;p&gt;$V(S_t)\leftarrow V(S_t)+\alpha(R_{t+1}+\gamma V(S_{t+1})-V(S_t))$&lt;/p&gt;

&lt;p&gt;式中：&lt;/p&gt;

&lt;p&gt;$R_{t+1}+\gamma V(S_{t+1})$称为TD目标值&lt;/p&gt;

&lt;p&gt;$\delta_t=R_{t+1}+\gamma V(S_{t+1})-V(S_t)$称为TD误差&lt;/p&gt;

&lt;p&gt;bootstrapping指的就是TD目标值代替收获$G_t$的过程。可以理解为“引导”。&lt;/p&gt;

&lt;h4 id=&quot;mc对比td&quot;&gt;MC对比TD&lt;/h4&gt;

&lt;p&gt;一个episode中，TD在知道结果之前可以学习，MC必须等到最后结果才能学习；也就是说，TD可以在持续进行的没有结果的环境中学习。&lt;/p&gt;

&lt;p&gt;MC使用的$G_t$是实际收获，是基于某一策略状态价值的无偏估计；而TD target是基于下一状态的预估价值计算的当前预估收获，是当前状态实际价值的有偏估计。如果用的是下一状态的实际价值来计算当前状态，那就是true TD target，是对当前状态实际价值的无偏估计：&lt;/p&gt;

&lt;p&gt;$R_{t+1}+\gamma v_{\pi}(S_{t+1})$&lt;/p&gt;

&lt;p&gt;TD算法使用了MDP问题的马尔可夫属性，在Markov环境下更有效；但MC算法并不利用马尔可夫属性，通常在非Markov环境下更有效。&lt;/p&gt;

&lt;h4 id=&quot;mctddp&quot;&gt;MC/TD/DP&lt;/h4&gt;

&lt;p&gt;MC与TD与DP都是计算MDP模型的状态价值的方法。前两种是在模型未知的情况下的常用方法，MC要完整的episode来更新状态价值，TD不需要完整的episode；DP方法是在模型已知时使用的计算状态价值的方法，通过计算一个状态$S$所有可能的转移状态$S’$及其转移概率以及对应的即时奖励来计算这个状态$S$的价值。&lt;/p&gt;

&lt;p&gt;MC没有引导数据，只使用实际收获；DP和TD都有引导数据。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/DP_view.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/MC_view.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/TD_view.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;model-free-control&quot;&gt;Model-free control&lt;/h3&gt;

&lt;p&gt;这里不基于模型的控制指为一个未知的MDP最优化其价值函数。&lt;/p&gt;

&lt;h4 id=&quot;policy-iteration&quot;&gt;Policy Iteration&lt;/h4&gt;

&lt;p&gt;通用策略迭代的核心是在两个交替的过程之间进行策略优化。一个过程是策略评估，另一个是改善策略。从一个策略$\pi$和一个价值函数$V$开始，每一次箭头向上代表着利用当前策略进行价值函数的更新，每一次箭头向下代表着根据更新的价值函数贪婪地选择新的策略，说它是贪婪的，是因为每次都采取转移到可能的、状态函数最高的新状态的行为。最终将收敛至最优策略和最优价值函数。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/policy_iter.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这种方法不适用于模型未知的蒙特卡洛学习。我们需要使用状态行为对下的价值$Q(s,a)$来代替状态价值，这样做的目的是可以改善策略而不用知道整个模型，只需要知道在某个状态下采取什么样的行为价值最大即可。具体是这样：从一个初始的$Q$和策略$\pi$开始，先根据这个策略更新每一个状态行为对的$q$值，$s$随后基于更新的$Q$确定改善的贪婪算法。&lt;/p&gt;

&lt;p&gt;但如果我们每次都贪婪地改善策略，很有可能会导致采样经验不足，从而产生一个并不是最优的策略。我们需要不时地尝试一些新的行为，$\epsilon$-exploration就是一个折中的探索方案：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/epsilon_explore.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;sarsa-on-policy-td-control&quot;&gt;SARSA: On-policy TD Control&lt;/h4&gt;

&lt;p&gt;SARSA算法是一种在控制问题中使用TD学习方法来获得状态行为价值$Q$的估计的算法。&lt;/p&gt;

&lt;p&gt;SARSA是on-policy的：个体已有一个策略，并且遵循这个策略进行采样，或者说采取一系列该策略下产生的行为，根据这一系列行为得到的奖励，更新状态函数，最后根据该更新的价值函数来优化策略（一句话就是要优化的策略就是当前遵循的策略）。&lt;/p&gt;

&lt;p&gt;伪代码：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/SARSA.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在算法中，$Q(s,a)$是以一张大表存储的，这不适用于解决规模很大的问题。&lt;/p&gt;

&lt;h4 id=&quot;q-learning-off-policy-td-control&quot;&gt;Q-learning: Off-policy TD Control&lt;/h4&gt;

&lt;p&gt;off-policy与on-policy不同，off-policy的学习方法运行在两个policy上，一个target policy，一个behavior policy。off-policy学习是从behavior policy上采样得到经验从而改进target policy的，换句话说就是采用一个现有的policy，遵从它来与环境交互，获得数据，再利用这些数据来评估另一个policy。这种方法的好处能够在实际应用中体现出来，一个是能够从人类或其他智能体的经验中学习，另一个是能够从旧有的policy中学习。&lt;/p&gt;

&lt;p&gt;Q-learning是一种基于TD的off-policy的控制方法，要点在于：更新一个状态行为价值$Q$时，采用的不是当前遵循策略的下一个状态行为价值$Q’$，而是采用待评估策略产生的下一个状态行为价值$Q’$。公式：&lt;/p&gt;

&lt;p&gt;$Q(S_t,A_t)\leftarrow Q(S_t, A_t)+\alpha(R_{t+1}+\gamma Q(S_{t+1}, A’)-Q(S_t, A_t))$&lt;/p&gt;

&lt;p&gt;其中TD target是基于待评估策略产生的行为$A’$得到的$Q$价值。&lt;/p&gt;

&lt;p&gt;伪代码：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Q_learning.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上面的伪代码展示的是一种，将完全greedy地改进policy（下一状态选择最大Q对应的a作为行动）作为target policy的Q-learning&lt;/p&gt;</content><author><name>Jingwen Huang</name></author><category term="Reinforcement Learning" /><category term="Basics" /><summary type="html">主要参考陈旭老师的ppt以及知乎专栏https://www.zhihu.com/column/reinforce</summary></entry><entry><title type="html">读书笔记||神经网络与深度学习第3章</title><link href="https://uangjw.github.io/2021/10/22/book2-chap3/" rel="alternate" type="text/html" title="读书笔记||神经网络与深度学习第3章" /><published>2021-10-22T00:00:00+00:00</published><updated>2021-10-22T00:00:00+00:00</updated><id>https://uangjw.github.io/2021/10/22/book2-chap3</id><content type="html" xml:base="https://uangjw.github.io/2021/10/22/book2-chap3/">&lt;p&gt;《神经网络与深度学习》第三章粗略读书笔记&lt;/p&gt;

&lt;h3 id=&quot;交叉熵代价函数&quot;&gt;交叉熵代价函数&lt;/h3&gt;

&lt;p&gt;我们希望和期待神经网络可以从错误中快速地学习，而人工神经元再犯错较大的时候学习很有难度。我们的神经元是通过改变权重和偏置，并以一个代价函数的偏导数决定的速度学习。所以我们在说“学习缓慢”时，实际上就是说这些偏导数很小。这种情况实际上就是使用二次代价函数引起的。&lt;/p&gt;

&lt;p&gt;交叉熵代价函数可以用来解决上述问题。简单来说，交叉熵是非负的，在神经元达到很好的正确率时会接近0，更重要的是使用交叉熵代价函数时，权重与偏置的偏导数中将不再带有曲线函数的导数项，且将带有输出中的误差作为一个系数。这就意味着交叉熵函数能够使神经网络在误差更大的时候获得更快的学习速度，这一现象并不依赖于如何设置学习速率。&lt;/p&gt;

&lt;p&gt;对一个输出神经元，设其目标值为$y=y_1,y_2,…$，实际输出值为$a^L_1,a^L_2,…$，那么可以定义交叉熵如下：&lt;/p&gt;

&lt;p&gt;$C=-\frac{1}{n}\sum_x\sum_j[y_j\ln a^L_j+(1-y_j)\ln(1-a^L_j)]$&lt;/p&gt;

&lt;p&gt;在一些文献中，交叉熵代价函数可以这样表达：&lt;/p&gt;

&lt;p&gt;$L=\sum_x\sum_j CE(I(x,j),P(x,j))$&lt;/p&gt;

&lt;p&gt;$L$为代价函数，$CE$表示交叉熵，$I(x,j)$是标志值，$P(x,j)$是实际输出值。&lt;/p&gt;

&lt;p&gt;有一种源自信息论的解释交叉熵的标准方式。粗略地说，交叉熵是“不确定性”的一种度量。&lt;/p&gt;

&lt;h3 id=&quot;过度拟合与规范化&quot;&gt;过度拟合与规范化&lt;/h3&gt;

&lt;p&gt;拥有大量自由参数的模型能够描述特别神奇的现象，即使这样的模型能够很好地拟合已有的数据，但并不表示是一个好模型。因为这可能只是因为模型中足够的自由度使得它可以描述几乎所有给定大小的数据集，而不需要真正洞察现象的本质。所以发生这种情形时，模型对已有的数据会表现得很好，但是对新的数据很难泛化。对一个模型真正的测验就是对它没有见过的场景的预测能力。&lt;/p&gt;

&lt;h4 id=&quot;过度拟合&quot;&gt;过度拟合&lt;/h4&gt;

&lt;p&gt;检测过度拟合的明显方法是跟踪测试数据集合上的准确率随训练变化情况，如果看到测试数据上的准确率不再提升，那么就停止训练。但严格来说这并非是过度拟合的一个必要现象，因为测试集和训练集上的准确率可能会同时停止提升。&lt;/p&gt;

&lt;p&gt;书本为了更好地说明问题，举了识别手写数字图像的例子。在所使用的MNIST数据集中，我们载入了三个数据集：&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;test_data&lt;/code&gt;，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;training_data&lt;/code&gt;，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;validation_data&lt;/code&gt;。其中&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;validation_data&lt;/code&gt;（验证集）是用来防止过度拟合的，我们用它来衡量不同的超参数（如迭代器、学习速率、最好的网络架构等）的选择的效果，用这种方法来找到超参数的合适值。这么做的原理是，如果我们设置超参数是基于&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;test_data&lt;/code&gt;的话，可能最终我们就会得到过度拟合于&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;test_data&lt;/code&gt;的超参数；即我们可能会找到那些符合&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;test_data&lt;/code&gt;特点的超参数，但网络的性能并不能够泛化到其他数据集合上。使用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;validation_data&lt;/code&gt;训练获得想要的超参数之后，最终就使用&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;test_data&lt;/code&gt;进行准确率测量，这种寻找好的超参数的方法有时候被称为hold out方法。&lt;/p&gt;

&lt;p&gt;不过一般来说，最好的降低过度拟合的方式之一还是增加训练样本的量。有了足够的训练数据，就算是一个规模非常大的网络也不大容易过度拟合。&lt;/p&gt;

&lt;h4 id=&quot;规范化&quot;&gt;规范化&lt;/h4&gt;

&lt;p&gt;只有一个固定的网络和固定的训练集合时，可以使用规范化的技术来缓解过度拟合。一种最为常用的规范化手段叫权重衰减（weight decay）或L2规范化。&lt;/p&gt;

&lt;p&gt;L2规范化的想法是增加一个额外的项到代价函数上，这个额外的项叫做规范化项。规范化的交叉熵代价函数如下所示：&lt;/p&gt;

&lt;p&gt;$C=-\frac{1}{n}\sum_{x j}[y_j\ln a_j^L+(1-y_j)\ln(1-a_j^L)]+\frac{\lambda}{2n}\sum_w w^2$&lt;/p&gt;

&lt;p&gt;上式第二个项是所有权重的平方和乘上一个用于量化调整的因子。$\lambda&amp;gt;0$是规范化参数，$n$是训练集合的大小。需要注意的是规范化项中不包含偏置。&lt;/p&gt;

&lt;p&gt;直觉地看规范化的效果是让网络倾向于学习小一点的权重；大的权重只有能够给出代价函数第一项足够的提升时才被允许。规范化可以当作一种寻找小的权重和最小化原始的代价函数之间的折中，这两部分之间相对的重要性由$\lambda$的值来控制。&lt;/p&gt;

&lt;p&gt;这种规范化手段之所以又叫权重衰减，是因为在规范化的代价函数权重的梯度下降学习规则中，权重$w$前面多了一个因子$1-\frac{η\lambda}{n}$&lt;/p&gt;

&lt;p&gt;实践表明，规范化不仅是一种减轻过度拟合和提高分类准确率的方法，还能够使规范化后的网络受局部最优的干扰减少，从而提供更容易复制的结果。&lt;/p&gt;

&lt;p&gt;一句话解释规范化减轻过度拟合的原理：小的权重在某种程度上意味着更低的复杂性，也就对数据给出了一种更简单却更强大的解释，因此应该优先选择。这样说实在是太懒了，之后可能在想明白梯度下降法之后再来进一步解释。&lt;/p&gt;</content><author><name>Jingwen Huang</name></author><category term="Deep Learning" /><category term="BookReport" /><category term="Basics" /><summary type="html">《神经网络与深度学习》第三章粗略读书笔记</summary></entry><entry><title type="html">论文笔记||三个基于深度学习的音乐转录模型</title><link href="https://uangjw.github.io/2021/10/21/AMT-DL-3models/" rel="alternate" type="text/html" title="论文笔记||三个基于深度学习的音乐转录模型" /><published>2021-10-21T00:00:00+00:00</published><updated>2021-10-21T00:00:00+00:00</updated><id>https://uangjw.github.io/2021/10/21/AMT-DL-3models</id><content type="html" xml:base="https://uangjw.github.io/2021/10/21/AMT-DL-3models/">&lt;h1 id=&quot;三个基于深度学习的音乐转录模型&quot;&gt;三个基于深度学习的音乐转录模型&lt;/h1&gt;

&lt;p&gt;粗略了解三个模型，主要领会一下深度学习解决AMT问题的基本思想；总的来说本文是以下三篇论文的简要阅读笔记&lt;/p&gt;

&lt;p&gt;An End-to-End Neural Network for Polyphonic Piano Music Transcription（2016）&lt;/p&gt;

&lt;p&gt;Onsets and Frames: Dual-Objective Piano Transcription（2018谷歌）&lt;/p&gt;

&lt;p&gt;High-resolution Piano Transcription with Pedals by Regressing Onset and Offset Times（2020字节）&lt;/p&gt;

&lt;p&gt;除了文章本身，还参考了一琳同学的周报和舒心师姐的周报&lt;/p&gt;

&lt;h2 id=&quot;an-end-to-end-neural-network-for-polyphonic-piano-music-transcription&quot;&gt;An End-to-End Neural Network for Polyphonic Piano Music Transcription&lt;/h2&gt;

&lt;p&gt;一个CNN与RNN结合的端到端的钢琴演奏音乐转录模型。模型分为两部分：声学模型（acoustic model）与音乐语言模型（music language model）；这个模型结构是与语音识别系统类同的。声学模型与音乐语言模型之间通过一个概率图模型组合起来，最后使用波束搜索算法来在模型的输出上得到推断结果。&lt;/p&gt;

&lt;p&gt;本文总结了一些过去的AMT（自动音乐转录）模型，所提出的模型也是后续许多新模型的基础。&lt;/p&gt;

&lt;h3 id=&quot;声学模型&quot;&gt;声学模型&lt;/h3&gt;

&lt;p&gt;声学模型输入特征$x$，输出$P(y$|$x)$，其中$y$是一个高维向量，其分量分别对应于$x$在钢琴键的各音高上的可能性。经过一番讨论，最终文章选用的声学模型是一个卷积神经网络。选择CNN的原因主要是它在为输入音频的一个帧做出音高预测时，能够同时提取与这一帧相邻的多个帧的时域与频域特征，这与音乐的特性是相适应的。&lt;/p&gt;

&lt;h3 id=&quot;音乐语言模型&quot;&gt;音乐语言模型&lt;/h3&gt;

&lt;p&gt;音乐语言模型的输入是音符的时间序列$y$（$y_t$是一个高维二值向量，表示$t$时刻所有活跃的音高），输出是$y$的概率分布$P(y)$。对于多调音乐（polyphonic music），同时活跃的音高是具有高度的相关性的，它们可能组成一个和弦，或是满足某一调式。&lt;/p&gt;

&lt;p&gt;序列$y$的每一个值都是一个能表示钢琴所有音高中哪一个正在活跃的高维向量，要为这样的序列生成概率分布，需要使用RNN与NADE结合的模型。RNN与NADE都可以为输入找到概率分布，但RNN是为一个序列寻找，NADE是为一组高维输入寻找。直接使用RNN来为高维向量序列推测概率分布，则向量的各分量之间依然是独立的，在AMT问题里就相当于独立地看待同一时刻下活跃的音符，这就没有将音律的问题利用起来；而NADE在推测概率分布时并不考虑输入的顺序，即它将输入看作是一个无序的组而不是有序的序列。两者结合的RNN-NADE模型就能够比较好地推测高维向量时间序列的分布，结合方式简单来说就是让一系列的NADE在RNN的约束下学习。&lt;/p&gt;

&lt;h3 id=&quot;hybrid-rnn&quot;&gt;Hybrid RNN&lt;/h3&gt;

&lt;p&gt;将声学模型和音乐语言模型用概率图模型组合起来，就得到本文真正要提出的Hybrid RNN模型。在独立性假设&lt;/p&gt;

&lt;p&gt;$P(y_t$|$y^{t-1}_0, x^{t-1}_0)=P(y_t$|$y_0^{t-1})$&lt;/p&gt;

&lt;p&gt;$P(x_t$|$y_0^t,x_0^{t-1})=P(x_t$|$y_t)$&lt;/p&gt;

&lt;p&gt;下可以得到&lt;/p&gt;

&lt;p&gt;$P(y$|$x)\propto P(y_0$|$x_0)\prod^T_{t=1}P(y_t$|$y_0^{t-1})P(y_t$|$x_t)$&lt;/p&gt;

&lt;p&gt;其中$P(y_t$|$x_t)$即输入$x_t$时对输出的预测，通过声学模型得到；$P(y_t$|$y_0^{t-1})$即序列中考虑前后全部序列信息后对输出的预测，通过音乐语言模型得到。&lt;/p&gt;

&lt;h3 id=&quot;conclusions-and-future-work&quot;&gt;Conclusions and Future Work&lt;/h3&gt;

&lt;p&gt;作者提出的部分问题与未来改进方向：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;AMT问题的有标签数据集太少&lt;/li&gt;
  &lt;li&gt;输入目前用的是CQT，改用VQT等具有更高时间分辨率的输入表示可能有帮助（2020年有个工作Automatic Music Transcription for Two Instruments based Variable Q-Transform and Deep Learning methods）&lt;/li&gt;
  &lt;li&gt;音乐语言模型里对调式的考虑还不够，可以对模型使用变调的输入来训练，或者是针对不同调式训练不同的模型&lt;/li&gt;
  &lt;li&gt;音乐语言模型的网络结构还可以改进，比如把输入层改成卷积层&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;onsets-and-frames-dual-objective-piano-transcription&quot;&gt;Onsets and Frames: Dual-Objective Piano Transcription&lt;/h2&gt;

&lt;p&gt;这是一个利用深度卷积与循环神经网络赖完成多调的钢琴演奏转录工作的项目。这一模型的特别之处在于，它预测音高的开始事件（onset），然后利用这些预测来训练音高的逐帧识别；具体来说，就是在一个帧里，帧识别器不能推理一个音符的开始，除非onset检测器认可这一帧中存在onset。在训练模型的过程中，作者注意同时加强onset以及偏移量（指音符持续量）的检测效果。&lt;/p&gt;

&lt;p&gt;需要注意这里是对钢琴音符做起始位置识别；之所以能够这样做来提高AMT模型准确率，很大程度上还是和钢琴音符本身的特点有关系。钢琴音符的起始位置恰好就是音符振幅的峰值，且具有标志性的宽带频谱，所以识别钢琴演奏中的音符起始位置比较简单；同时钢琴敲键发声的原理也使得模型能够根据音符起始事件发生的速度来推断音符的音量，敲键快通常意味着这一音符的音量大，利用这一点转录生成的音频能够更好地记录钢琴演奏中的强度变化，结果更自然有感情（实际上演奏强度本来就是钢琴谱的一部分，如果说AMT的直接目的就是生成琴谱，那演奏强度本来就应该记录下来）。&lt;/p&gt;

&lt;h3 id=&quot;网络框架&quot;&gt;网络框架&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/images/google_AMT_model.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;模型的输入为229 mel-bins，2048 FFT Window size，16000Hz采样率的频谱结果。&lt;/p&gt;

&lt;p&gt;onset检测器：卷积层的输出作为128 units双向LSTM的输入，LSTM后接一个88维输出的全连接层，88维的输出表示88个钢琴音高的onset概率&lt;/p&gt;

&lt;p&gt;framewise检测器：卷积层接一个88维输出的全连接层，88维的输出向量和onset检测器端的对88个音高的onset预测向量级联成一个176维的向量，再过一个88维输出的全连接层。&lt;/p&gt;

&lt;p&gt;LSTM（long short term网络）是一种特殊的RNN，它和简单RNN相比能够学习到连接更远的信息；双向的RNN是由两个RNN上下叠加在一起组成的，对于每个时刻t，输入会同时提供给两个方向相反的RNN，输出由两个RNN的状态共同决定，双向LSTM也是一样的。&lt;/p&gt;

&lt;h3 id=&quot;损失函数&quot;&gt;损失函数&lt;/h3&gt;

&lt;p&gt;好复杂，没懂，待补充……&lt;/p&gt;

&lt;h2 id=&quot;high-resolution-piano-transcription-with-pedals-by-regressing-onset-and-offset-times&quot;&gt;High-resolution Piano Transcription with Pedals by Regressing Onset and Offset Times&lt;/h2&gt;

&lt;p&gt;如题目所说，与谷歌的项目相比提高了onset检测的时间分辨率（从帧到毫秒），且增加了对延音踏板的转录。&lt;/p&gt;

&lt;p&gt;为什么要提高onset检测的分辨率？以谷歌的模型为例，它只找到并标出onset事件发生的帧，不能给出具体发生的时刻，进而不能给出音符attack的持续时间；另一方面，很自然的，对于逐帧的转录模型的转录结果，其分辨率会受帧长选择的影响，为了提高结果的时间分辨率而一味缩短帧长又会提高计算开销。&lt;/p&gt;

&lt;p&gt;本文提高检测分辨率的方式是，定义每帧的target值为此帧的中间时刻到最近的onset时刻的时间。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/HigherOnsetResolution.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;网络框架-1&quot;&gt;网络框架&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/images/ByteDance_AMT_model.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;还看不太懂，待补充……&lt;/p&gt;</content><author><name>Jingwen Huang</name></author><category term="Deep Learning" /><category term="PaperNotes" /><category term="AMT" /><summary type="html">三个基于深度学习的音乐转录模型</summary></entry><entry><title type="html">读书笔记||神经网络与深度学习5、6章</title><link href="https://uangjw.github.io/2021/10/21/book2-chap56/" rel="alternate" type="text/html" title="读书笔记||神经网络与深度学习5、6章" /><published>2021-10-21T00:00:00+00:00</published><updated>2021-10-21T00:00:00+00:00</updated><id>https://uangjw.github.io/2021/10/21/book2-chap56</id><content type="html" xml:base="https://uangjw.github.io/2021/10/21/book2-chap56/">&lt;h3 id=&quot;第五章-深度神经网络为何很难训练&quot;&gt;第五章 深度神经网络为何很难训练&lt;/h3&gt;

&lt;p&gt;深度神经网络：更多的隐藏层&lt;/p&gt;

&lt;p&gt;深度网络中，不同的层学习的速度差异很大&lt;/p&gt;

&lt;p&gt;深度神经网络中使用基于梯度下降的学习方法本身存在着内在不稳定性。这种不稳定性使得先前或者后面的层的学习过程阻滞&lt;/p&gt;

&lt;p&gt;观察隐藏层之间学习速度的差异，有这样一个结果：前面隐藏层中的神经元学习速度要慢于后面的隐藏层——消失的梯度问题（vanishing gradient problem）；一个不好的解决方法又会导致前面的层中的梯度变得非常大——激增的梯度问题（exploding gradient problem）&lt;/p&gt;

&lt;p&gt;深度神经网络中的梯度是不稳定的，在前面的层中或消失或激增&lt;/p&gt;

&lt;h4 id=&quot;梯度不稳定性&quot;&gt;梯度不稳定性&lt;/h4&gt;

&lt;p&gt;前面的层上的梯度是来自后面的层上项的乘积，当存在过多的层次时，就出现了内在本质上的不稳定场景。所以如果使用标准的基于梯度的学习算法，在网络中的不同层就会出现按照不同学习速度学习的情况&lt;/p&gt;

&lt;p&gt;总之“什么让训练深度网络非常困难”这个问题相当复杂，除了基于梯度的学习方法是不稳定的，激活函数的选择，权重初始化甚至是学习算法的实现方式也扮演了重要的角色。网络结构和其他超参数本身也是很重要的。&lt;/p&gt;

&lt;h3 id=&quot;第六章-深度学习&quot;&gt;第六章 深度学习&lt;/h3&gt;

&lt;p&gt;本章主要的部分是介绍深度卷积网络&lt;/p&gt;

&lt;p&gt;卷积神经网络是一个设法利用空间结构的架构（在解决图像识别问题的角度上）&lt;/p&gt;

&lt;p&gt;卷积神经网络采用三种基本概念：局部感受野local receptive fields，共享权重shared weights，混合pooling&lt;/p&gt;

&lt;p&gt;在图像识别的场景下解释这三个概念：&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;局部感受野：&lt;/strong&gt;将输入像素（一幅图像）连接到一个隐藏神经元层，但并不把每个输入像素连接到每个隐藏神经元，只是把输入图像进行小的、局部区域的连接；确切来说，第一个隐藏层中的每个神经元会连接到一个输入神经元（像素）的小区域，这个区域就被称为隐藏神经元的局部感受野。它是输入像素上的一个小窗口，一个连接学习一个权重，而隐藏神经元同时也学习一个总的偏置。可以把这个特定的隐藏神经元看作是在学习分析它的局部感受野。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;共享权重和偏置：&lt;/strong&gt;局部感受野在原图像中按照所使用的跨距移动，构建起隐藏层，其中每个隐藏神经元具有一个偏置和连接到它的局部感受野的逐像素权重，且这一隐藏层中所有神经元都使用相同的权重与偏置。输入层到隐藏层的映射被称为一个&lt;strong&gt;特征映射&lt;/strong&gt;，定义特征映射的权重称为共享权重，偏置称为共享偏置。共享权重和偏置经常被称为一个&lt;strong&gt;卷积核&lt;/strong&gt;或者&lt;strong&gt;滤波器&lt;/strong&gt;。共享权重和偏置的一个很大的优点是，它大大减少了参与的卷积网络的参数。&lt;/p&gt;

&lt;p&gt;共享权重和偏置的使用意味着一个隐藏层中所有神经元检测完全相同的特征，只是在输入图像的不同位置；这能很好地适应图像的平移不变性。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;混合层：&lt;/strong&gt;又名池化层（pooling layer），通常紧接着在卷积层之后使用。它要做的是简化从卷积层输出的信息。混合层取得从卷积层输出的每一个特征映射（指隐藏神经元从该层输出的激活值），并从它们准备一个凝缩的特征映射。混合层的每一个单元会用来概括前一层的某个区域的神经元，例如最大值混合（max-pooling）就将这一个区域中的最大激活值输出。&lt;/p&gt;

&lt;p&gt;另一个常用的混合方法是L2混合，它取区域中激活值的平方和的平方根。&lt;/p&gt;

&lt;p&gt;一个典型的图像识别卷积神经网络结构：一层输入神经元，这些神经元用于对图像的像素强度进行编码；一个卷积层，使用axa的局部感受野和b个特征映射；一个最大值混合层，应用于cxc区域，遍及b个特征映射。网络中最后连接的层是一个全连接层。这一层将最大值混合层的每一个神经元连接到每一个输出神经元。&lt;/p&gt;

&lt;h3 id=&quot;补充&quot;&gt;补充&lt;/h3&gt;

&lt;h4 id=&quot;循环神经网络rnn&quot;&gt;循环神经网络RNN&lt;/h4&gt;

&lt;p&gt;参考：https://zybuluo.com/hanbingtao/note/541458&lt;/p&gt;

&lt;p&gt;对于某些任务，它们要求能够更好地处理序列的信息，即前面的输入和后面的输入是有关系的；RNN就是为了适应这样的任务提出的。&lt;/p&gt;

&lt;p&gt;基本循环神经网络的计算方法可以用下面的公式表示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/RNNeq.png&quot; style=&quot;zoom:67%;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;该网络在t时刻接收到输入$x_t$之后，隐藏层的值是$s_t$，输出值是$o_t$，$s_t$的值不仅仅取决于$x_t$，还取决于$s_{t-1}$。式1是输出层的计算公式，输出层是一个全连接层，$V$是输出层的权重矩阵，$g$是激活函数。式2是隐藏层的计算公式，它是循环层。$U$是输入x的权重矩阵，$W$是上一次的值$s_{t-1}$作为这一次的输入的权重矩阵，$f$是激活函数。&lt;/p&gt;

&lt;p&gt;循环层与全连接层的区别就是循环层多了一个权重矩阵W，反复把式2代入式1就可以看到，循环神经网络的输出值$o_t$是受前面历次输入值$x_t$、$x_{t-1}$、$x_{t-2}$、……影响的，这就是为什么循环神经网络可以注意到前面任意多个输入值的原因。&lt;/p&gt;</content><author><name>Jingwen Huang</name></author><category term="Deep Learning" /><category term="BookReport" /><category term="Basics" /><summary type="html">第五章 深度神经网络为何很难训练 深度神经网络：更多的隐藏层 深度网络中，不同的层学习的速度差异很大 深度神经网络中使用基于梯度下降的学习方法本身存在着内在不稳定性。这种不稳定性使得先前或者后面的层的学习过程阻滞 观察隐藏层之间学习速度的差异，有这样一个结果：前面隐藏层中的神经元学习速度要慢于后面的隐藏层——消失的梯度问题（vanishing gradient problem）；一个不好的解决方法又会导致前面的层中的梯度变得非常大——激增的梯度问题（exploding gradient problem） 深度神经网络中的梯度是不稳定的，在前面的层中或消失或激增 梯度不稳定性 前面的层上的梯度是来自后面的层上项的乘积，当存在过多的层次时，就出现了内在本质上的不稳定场景。所以如果使用标准的基于梯度的学习算法，在网络中的不同层就会出现按照不同学习速度学习的情况 总之“什么让训练深度网络非常困难”这个问题相当复杂，除了基于梯度的学习方法是不稳定的，激活函数的选择，权重初始化甚至是学习算法的实现方式也扮演了重要的角色。网络结构和其他超参数本身也是很重要的。 第六章 深度学习 本章主要的部分是介绍深度卷积网络 卷积神经网络是一个设法利用空间结构的架构（在解决图像识别问题的角度上） 卷积神经网络采用三种基本概念：局部感受野local receptive fields，共享权重shared weights，混合pooling 在图像识别的场景下解释这三个概念： 局部感受野：将输入像素（一幅图像）连接到一个隐藏神经元层，但并不把每个输入像素连接到每个隐藏神经元，只是把输入图像进行小的、局部区域的连接；确切来说，第一个隐藏层中的每个神经元会连接到一个输入神经元（像素）的小区域，这个区域就被称为隐藏神经元的局部感受野。它是输入像素上的一个小窗口，一个连接学习一个权重，而隐藏神经元同时也学习一个总的偏置。可以把这个特定的隐藏神经元看作是在学习分析它的局部感受野。 共享权重和偏置：局部感受野在原图像中按照所使用的跨距移动，构建起隐藏层，其中每个隐藏神经元具有一个偏置和连接到它的局部感受野的逐像素权重，且这一隐藏层中所有神经元都使用相同的权重与偏置。输入层到隐藏层的映射被称为一个特征映射，定义特征映射的权重称为共享权重，偏置称为共享偏置。共享权重和偏置经常被称为一个卷积核或者滤波器。共享权重和偏置的一个很大的优点是，它大大减少了参与的卷积网络的参数。 共享权重和偏置的使用意味着一个隐藏层中所有神经元检测完全相同的特征，只是在输入图像的不同位置；这能很好地适应图像的平移不变性。 混合层：又名池化层（pooling layer），通常紧接着在卷积层之后使用。它要做的是简化从卷积层输出的信息。混合层取得从卷积层输出的每一个特征映射（指隐藏神经元从该层输出的激活值），并从它们准备一个凝缩的特征映射。混合层的每一个单元会用来概括前一层的某个区域的神经元，例如最大值混合（max-pooling）就将这一个区域中的最大激活值输出。 另一个常用的混合方法是L2混合，它取区域中激活值的平方和的平方根。 一个典型的图像识别卷积神经网络结构：一层输入神经元，这些神经元用于对图像的像素强度进行编码；一个卷积层，使用axa的局部感受野和b个特征映射；一个最大值混合层，应用于cxc区域，遍及b个特征映射。网络中最后连接的层是一个全连接层。这一层将最大值混合层的每一个神经元连接到每一个输出神经元。 补充 循环神经网络RNN 参考：https://zybuluo.com/hanbingtao/note/541458 对于某些任务，它们要求能够更好地处理序列的信息，即前面的输入和后面的输入是有关系的；RNN就是为了适应这样的任务提出的。 基本循环神经网络的计算方法可以用下面的公式表示： 该网络在t时刻接收到输入$x_t$之后，隐藏层的值是$s_t$，输出值是$o_t$，$s_t$的值不仅仅取决于$x_t$，还取决于$s_{t-1}$。式1是输出层的计算公式，输出层是一个全连接层，$V$是输出层的权重矩阵，$g$是激活函数。式2是隐藏层的计算公式，它是循环层。$U$是输入x的权重矩阵，$W$是上一次的值$s_{t-1}$作为这一次的输入的权重矩阵，$f$是激活函数。 循环层与全连接层的区别就是循环层多了一个权重矩阵W，反复把式2代入式1就可以看到，循环神经网络的输出值$o_t$是受前面历次输入值$x_t$、$x_{t-1}$、$x_{t-2}$、……影响的，这就是为什么循环神经网络可以注意到前面任意多个输入值的原因。</summary></entry><entry><title type="html">论文笔记||Customizing Painterly Rendering Styles Using Stroke Processes</title><link href="https://uangjw.github.io/2021/04/05/paper-NPR-stroke-processes/" rel="alternate" type="text/html" title="论文笔记||Customizing Painterly Rendering Styles Using Stroke Processes" /><published>2021-04-05T00:00:00+00:00</published><updated>2021-04-05T00:00:00+00:00</updated><id>https://uangjw.github.io/2021/04/05/paper-NPR-stroke-processes</id><content type="html" xml:base="https://uangjw.github.io/2021/04/05/paper-NPR-stroke-processes/">&lt;p&gt;​本文提出的基于笔触方法对照片进行油画风格渲染的方法,主要聚焦于如何将感知层面上的油画风格特性（如笔触大小、色彩浓度等等）在“绘制”（stroke placement）的过程中体现到渲染结果里，从而实现在同一个模型中生成可以根据用户需求调整的不同风格的渲染效果。虽然前述才是本文的亮点，但本博客将主要尝试解说文章中利用马尔可夫邻接图以及随机反应扩散方程生成最终笔触效果的方法。&lt;/p&gt;

&lt;p&gt;[TOC]&lt;/p&gt;

&lt;h2 id=&quot;stroke-neighborhood-graph&quot;&gt;Stroke Neighborhood Graph&lt;/h2&gt;

&lt;h3 id=&quot;笔触邻接图&quot;&gt;笔触邻接图&lt;/h3&gt;

&lt;p&gt;​马尔可夫邻接图是一个无向图，它将一个具有马尔可夫性质的随机变量的集合用无向图的形式描述了出来；马尔可夫性质是指一个随机过程的无记忆性，即其未来状态只依赖于当前状态。具体而言，本文所使用的笔触邻接图（Markov stroke neighborhood graph）中每一个顶点都表示特定采样位置上的一个笔触（矩形），只有有边直接相连的顶点之间能够相互影响，在后续的属性过程中，反应扩散的信息将沿着这些边进行传递。一个与笔触邻接图类似的马尔科夫随机场的例子是这样一块菜地：任何一小块地里种的菜的种类仅仅与它临近的菜的种类有关，而与其他位置的菜的种类无关。本文采用了一种基于采样点间距离以及笔触取向（orientation）的各向异的邻接图生成规则；与各向同的规则相比，本方法能够生成边分布更均匀的邻接图，从而获得更好的渲染效果。&lt;/p&gt;

&lt;h3 id=&quot;生成&quot;&gt;生成&lt;/h3&gt;

&lt;p&gt;​笔触邻接图的生成在笔触位置图（stroke positions）的基础上分三步完成。第一步，由未经处理的原图像生成参考取向图（方法：diffusing segmentation boundaries and salient sketches）；第二步，按笔触为单位处理，以每一个笔触（矩形）的中心为原点建立直角坐标系，坐标轴的取向能够使得矩形的两对称轴与直线$x\pm y=0$重合。&lt;/p&gt;

&lt;p&gt;​第三步，按一各向异的规则将笔触的中心（即无向图的顶点）连接起来。对于每一个顶点及其在第二步中确定的直角坐标系，在各象限中找到一个距离原点最近的笔触中心并将其与原点连接；但每一个作为原点的笔触不一定会和恰好四个笔触连接起来，若某象限内的最近笔触与原点的距离超出了规定的值，该笔触将被忽略；若某象限内的最近笔触并不属于同一区域（图像的分割在笔触位置确定之前就已经完成），该笔触将被忽略；一个笔触在作为原点时可能已经与四个笔触相连了，但由于此方法的不对称性，可能会存在第五个笔触在以自身为原点时将前述笔触连接了起来，那么前述笔触就有了五个邻接笔触。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/screenshot0405_1.png&quot; div=&quot;&quot; align=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;attribute-processes-for-stroke-orientations-sizes-and-colors&quot;&gt;Attribute Processes for Stroke Orientations, Sizes and Colors&lt;/h2&gt;

&lt;p&gt;​笔触的取向、大小以及色调等信息都是通过笔触邻接图上迭代的反应扩散过程计算确定的。反应扩散系统（reaction-diffusion system）中最具代表性的例子就是化学反应中的空间与时间变化过程：局部的反应使得物质之间相互转化，而扩散使得物质在空间上发生移动（spread out）。从数学的角度来说，反应扩散方程是一个半线性的抛物型微分方程，具有一定的形式。具体到这里的笔触属性，“扩散”将使得各属性沿邻接的笔触相互作用，在迭代中不断降低对比度（或增强对比度）；“反应”则将在迭代中保持原图像中的基本信息。由于各属性的反应扩散过程基本差不多，而取向在其中较为特殊，所以下面主要梳理取向的反应扩散过程是如何进行的。&lt;/p&gt;

&lt;p&gt;​对于笔触取向$\theta$的反应扩散过程，相关公式列于下方：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/screenshot0405_3.png&quot; div=&quot;&quot; align=&quot;center&quot; /&gt;&lt;/p&gt;

&lt;p&gt;​其中（1）式即为笔触取向对应的反应扩散方程。$\frac{d\theta}{dt}$为笔触取向随时间的变化速率，$\epsilon_{\theta}$是一个用于模拟绘画中自然的随机性的随机噪声值，扩散率$\lambda_{\theta}$的取值受用户给定的“局部均匀性”（local isotropy）值决定。&lt;/p&gt;

&lt;p&gt;​$D(\theta)$即“扩散项”，具体定义为（2）式，$\theta_n$即为第n次迭代后该笔触的取向，$\omega_n$为与笔触间距离成反比的权重值。$D(\theta)$的定义源于取向值$\theta$本身以$2\pi$为周期的特征（由此采用的特定的定义形式）。&lt;/p&gt;

&lt;p&gt;​$R(\theta)$为“局部反应项”，由（3）式定义。$\theta^*$即每一笔触在前面提到的“参考取向图”中的取向。由定义可知，$R(\theta)$在每一次迭代中对迭代结果的取值都施加着来自原图像的影响（参考取向图完全来自原图像），也就起到了保持信息的作用。&lt;/p&gt;

&lt;p&gt;​在迭代的过程中，笔触邻接图需要根据每一次得到的新的$\theta_n$值进行更新（因为笔触邻接图的拓扑结构受笔触取向影响，前面已有解说）；随着$\theta_n$值的收敛，整个笔触邻接图（马尔科夫随机场）的场能将接近一个最小值（忽略随机噪声时可以计算达到，（4）式即忽略了噪声的场能计算式），此时的$\theta_n$就是笔触取向的最终结果。&lt;/p&gt;

&lt;h2 id=&quot;碎碎念&quot;&gt;碎碎念&lt;/h2&gt;

&lt;p&gt;​本篇论文的最大亮点应该是其将绘画（主要是油画）的感知层面的特征总结成了8个可以运算的参数，但由于本人知识积累不多，所以更倾向于总结整理文中具体生成结果的方法。个人感觉，这篇11年的工作所能生成的结果已经非常非常完美了（下面放了个论文附图），且其中的创新也是从“用户交互”“感知”层面来做的，纯技术的创新不多。我将我的感受和老师聊了一下，老师也说到非真实感渲染这一块的主观性比较强而技术发展比较完备，除了感知层面的创新以外，如果还想提出技术层面的新东西的话一般都是往这一领域引入新的方法（指出一个新的研究方向，比如用机器学习的方法来做就是一种创新）。但要是想基于传统图形学来提出新方法的话，就需要很多很多的积累，这也是师兄强调的一点。（和老师聊了一下子还听到一个有意思的：搞传统图形学的可能不太认可搞深度学习的，为什么呢？）总之接下来还是一边搞点感兴趣的东西看看一边系统地学习图形学吧。&lt;/p&gt;

&lt;p&gt;​这一篇博客也是我第一篇真正意义的博客，还不太知道怎么写；不过深一步地说，本质是还不太明白怎么阅读一篇论文。之前那些论文笔记实际上还是“翻译”的色彩浓一点，很多细节其实没有理解清楚，只是把英语表述的方法用中文复述了一遍而已。但如果是博客的话，说不定（只是说不定）会有人来观光，如果我的文字真的能帮助到一些困惑的同学的话那当然是再好不过了，要达到这一点首先写作者得把内容悟清楚，这么说也是对我自己的学习提出了更高的要求吧。不过一个大问题是目前的效率还是太低，心有余而力不足……慢慢来吧=D&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/screenshot0405_2.png&quot; div=&quot;&quot; align=&quot;center&quot; /&gt;&lt;/p&gt;</content><author><name>Jingwen Huang</name></author><category term="PaperNotes" /><summary type="html">​本文提出的基于笔触方法对照片进行油画风格渲染的方法,主要聚焦于如何将感知层面上的油画风格特性（如笔触大小、色彩浓度等等）在“绘制”（stroke placement）的过程中体现到渲染结果里，从而实现在同一个模型中生成可以根据用户需求调整的不同风格的渲染效果。虽然前述才是本文的亮点，但本博客将主要尝试解说文章中利用马尔可夫邻接图以及随机反应扩散方程生成最终笔触效果的方法。</summary></entry><entry><title type="html">论文笔记/复现||python-opencv实现数字绘画重打光（relighting）</title><link href="https://uangjw.github.io/2021/03/01/reproduction-PaintingLight/" rel="alternate" type="text/html" title="论文笔记/复现||python-opencv实现数字绘画重打光（relighting）" /><published>2021-03-01T00:00:00+00:00</published><updated>2021-03-01T00:00:00+00:00</updated><id>https://uangjw.github.io/2021/03/01/reproduction-PaintingLight</id><content type="html" xml:base="https://uangjw.github.io/2021/03/01/reproduction-PaintingLight/">&lt;p&gt;​	Project PaintingLight(&lt;a href=&quot;https://github.com/lllyasviel/PaintingLight&quot;&gt;https://github.com/lllyasviel/PaintingLight&lt;/a&gt;) 通过色彩几何（color geometry）的方法实现了对数字绘画进行重打光（relighting）的功能；算法的核心在于定义并测量了图像的笔触密度（stroke density），从而以此为基础生成与给定光源位置对应的打光效果。整个项目可以大致分为定义并测量笔触密度、生成大致光照图像以及生成最终图像三个部分。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;定义并测量笔触密度&lt;/p&gt;

    &lt;p&gt;​	作者们发现在数字绘画的创作过程中大致有这样的规律：画家往往会通过用色彩不断“加深”的方式来绘制阴影的效果，即色彩混合程度较高的区域（用原文的话来说是“笔触历史较密集”的区域）通常就是阴影的区域。从这里我们也可以明显地看出，这一出发点将使得本算法对使用大色块绘制（flat）的数字绘画将无可奈何，而只对使用“厚涂”技法的作品能展现出最好的效果；进一步地，“厚涂”作品往往与真实照片接近，因此我们也可以推测本算法在对照片的重打光场景下也有施展的空间。&lt;/p&gt;

    &lt;p&gt;​	作者将笔触密度stroke density定义如下：&lt;/p&gt;

    &lt;p&gt;​	\(k=\frac{1-\sqrt{\sum^n_{i=1}{\alpha^2_i}}}{1-\frac{1}{\sqrt{n}}}\)&lt;/p&gt;

    &lt;p&gt;​	将组成源图像的所有色彩（像素值，一个色彩空间中的向量）的集合称为一个调色盘palette，那么其中的每一个特定的颜色实际上都可以由整个调色盘中的色彩值加权求和得到，上式中的$\alpha_i$就是这一“权值”。通过建立基于凸包的调色盘并利用其几何特性，简单推导后就可得到每一色彩$\boldsymbol{c}_p$与调色盘元素的关系如下：&lt;/p&gt;

    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;​	$$\begin{aligned}\boldsymbol{c}_p&amp;amp;=(1-\frac{&lt;/td&gt;
          &lt;td&gt;\boldsymbol{c}_p-\boldsymbol{g}&lt;/td&gt;
          &lt;td&gt;}{&lt;/td&gt;
          &lt;td&gt;\boldsymbol{h}_p-\boldsymbol{g}&lt;/td&gt;
          &lt;td&gt;})\boldsymbol{g}+(\frac{&lt;/td&gt;
          &lt;td&gt;\boldsymbol{c}_p-\boldsymbol{g}&lt;/td&gt;
          &lt;td&gt;}{&lt;/td&gt;
          &lt;td&gt;\boldsymbol{h}_p-\boldsymbol{g}&lt;/td&gt;
          &lt;td&gt;})\boldsymbol{h}_p\&amp;amp;=(\frac{\boldsymbol{c}_p-\boldsymbol{g}}{&lt;/td&gt;
          &lt;td&gt;\boldsymbol{h}_p-\boldsymbol{g}&lt;/td&gt;
          &lt;td&gt;})\boldsymbol{h}&lt;em&gt;p+\frac{1}{n}\sum^n&lt;/em&gt;{i=1}{\frac{&lt;/td&gt;
          &lt;td&gt;\boldsymbol{c}_i-\boldsymbol{g}&lt;/td&gt;
          &lt;td&gt;}{&lt;/td&gt;
          &lt;td&gt;\boldsymbol{h}_i-\boldsymbol{g}&lt;/td&gt;
          &lt;td&gt;}}\end{aligned}$$&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;

    &lt;p&gt;上式中$\boldsymbol{g}$为调色盘的重心$\frac{1}{n}\sum^n_{i=1}{\boldsymbol{c}_i}$，$\boldsymbol{h}$为以$\boldsymbol{g}$为起点，经过特定像素值$\boldsymbol{c}_p$的射线与调色盘对应凸包的交点（坐标）。由上式可以看出，权值$\alpha$即为$\boldsymbol{c}_i$的系数，代入stroke density的定义式后可以得到表达式：&lt;/p&gt;

    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;​	$$k_p=\frac{&lt;/td&gt;
          &lt;td&gt;\boldsymbol{c}_p-\boldsymbol{g}&lt;/td&gt;
          &lt;td&gt;}{&lt;/td&gt;
          &lt;td&gt;\boldsymbol{h}_p-\boldsymbol{g}&lt;/td&gt;
          &lt;td&gt;}$$&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;

    &lt;p&gt;于是便可以估计得出源图像的stroke density分布。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;生成大致光照图像&lt;/p&gt;

    &lt;p&gt;​	作者注意到画家在绘制光影效果时往往先绘制出一个大致的忽略轮廓与边缘的光影效果，于是设计算法在生成光影效果时也同样地首先生成大致图像。在源代码中，作者使用高斯金字塔与sobel算子搭配来生成能体现微弱轮廓特征的大致的光照效果；此时暂未考虑光源位置的信息。在考虑光源位置对光照效果图像的影响时，作者指出&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;Each peak of the wave function $n_i^*(\boldsymbol{l},\theta,p_d)$ has a side facing the light source and a side facing away from the light source. We can increase the intensity of the front side and reduce the intensity of the back side to simulate a light&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;其中$\boldsymbol{l}$为光源位置的坐标，$\theta$与$p_d$是体现光源在图像上的投影坐标与特定像素坐标之间位置关系的变量。这一部分我暂时还是不太理解，看到作者在后文提到其做法类似shape-from-shadow algorithm，我想先了解一下后者，或许能够解开我这里的困惑。总之最终的做法是，将前述wave function的单位方向向量以及光源到待确定像素的单位方向向量做点乘运算，结果就是最终的考虑了光源位置的大致光照图像。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;生成最终图像&lt;/p&gt;

    &lt;p&gt;​	在生成最终图像时，根据笔触密度大处倾向于具有“高光”或“阴影”效果的规律，最终的光照效果图像$\boldsymbol{S}$可由下式计算得到：&lt;/p&gt;

    &lt;p&gt;​	\(\boldsymbol{S}_i=\gamma \boldsymbol{E}_i\odot \boldsymbol{K}+O\)&lt;/p&gt;

    &lt;p&gt;其中$\boldsymbol{E}$即已考虑了光源位置的大致光照效果图像，$\boldsymbol{K}$为各像素笔触密度stroke density的值所对应的灰度图像，$\gamma$为光照强度参数。$O$为环境强度参数（ambient intensity），其意义是在具有较小笔触密度值的区域模拟环境光的效果。在实际实现中，作者是先生成不考虑光源而考虑笔触密度的光照图像后再将其与用户鼠标指示的光源位置信息（光源坐标向量）作运算，得到最终的光照图像。渲染结果由光照图像与原图像各像素值对应相乘即得。&lt;/p&gt;

    &lt;p&gt;​	大致运行结果如下。代码见&lt;a href=&quot;https://github.com/uangjw/Reproduction-of-PaintingLight&quot;&gt;https://github.com/uangjw/Reproduction-of-PaintingLight&lt;/a&gt; &lt;br /&gt;
&lt;img src=&quot;/images/RelightingResult.png&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;</content><author><name>Jingwen Huang</name></author><category term="reproduction" /><category term="PaperNotes" /><category term="opencv" /><summary type="html">​ Project PaintingLight(https://github.com/lllyasviel/PaintingLight) 通过色彩几何（color geometry）的方法实现了对数字绘画进行重打光（relighting）的功能；算法的核心在于定义并测量了图像的笔触密度（stroke density），从而以此为基础生成与给定光源位置对应的打光效果。整个项目可以大致分为定义并测量笔触密度、生成大致光照图像以及生成最终图像三个部分。</summary></entry><entry><title type="html">了解Kuwahara Filter</title><link href="https://uangjw.github.io/2020/12/17/basic-KuwaharaFilter/" rel="alternate" type="text/html" title="了解Kuwahara Filter" /><published>2020-12-17T00:00:00+00:00</published><updated>2020-12-17T00:00:00+00:00</updated><id>https://uangjw.github.io/2020/12/17/basic-KuwaharaFilter</id><content type="html" xml:base="https://uangjw.github.io/2020/12/17/basic-KuwaharaFilter/">&lt;p&gt;​	Kuwahara filter是一种非线性的平滑滤波器。其主要特点是能够在保持边缘的前提下对图像进行平滑处理。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Kuwahara Operator&lt;/p&gt;

    &lt;p&gt;​	假设$ I(x,y) $是一个灰度图像，Kuwahara filter在其中以像素$ (x,y) $为中心取一个边长为$ 2a+1 $的正方形。这一正方形（window）可以被分成四个子区域（subregion），它们可以被表示为：&lt;/p&gt;

    &lt;p&gt;​	\(Q_i(x,y)=\begin{cases}[x,x+a]\times[y,y+a] \hspace{1em} \rm{if} \ \textit{i}=1 \\[x-a,x]\times[y,y+a] \hspace{1em} \rm{if} \ \textit{i}=2 \\[x-a,x]\times[y-a,y] \hspace{1em} \rm{if} \ \textit{i}=3 \\[x,x+a]\times[y-a,y] \hspace{1em} \rm{if} \ \textit{i}=4\end{cases}\)&lt;/p&gt;

    &lt;p&gt;一个区域划分的例子如下图所示，需注意a、b、c、d四个区域是有一定的重叠部分的。&lt;/p&gt;

    &lt;p&gt;​	分别计算四个区域的算术平均值$ m_i(x,y) $与标准差$ \sigma_i(x,y) $，其中标准差最小的区域所具有的算术平均值就成为window中心像素$ (x,y) $的值，也即四个区域中最“均匀”的部分的算数平均值就被取作中心像素的值。记Kuwahara filter的输出值为$ \varPhi (x,y) $，则Kuwahara filter的处理过程可表示为$ \varPhi(x,y)=m_i(x,y) $，其中$ i= \mathop{\arg\min}_{j} \sigma_j(x,y)$。&lt;/p&gt;

    &lt;p&gt;​	像素$ (x,y) $所在位置与边缘的关系对于判断哪一个子区域具有最小标准差来说非常重要。当像素恰落在边缘上时，其所取的值将是来自更平滑的区域的。与中值滤波一样，Kuwahara filter使用一个滑动窗口（sliding window）来处理图像的每一个像素，滑动窗口的大小是事先指定的，其值将影响生成图片的模糊程度。通常取具有奇数边长的正方形作为窗口（实际上也有长方形的窗口，子区域之间也并不非要重叠或一样大，只要能把整个窗口都覆盖住就可以了）。&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/images/window.png&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;彩色图像&lt;/p&gt;

    &lt;p&gt;​	使用Kuwahara filter处理彩色图像（RGB）时，不能通过对每个通道分别使用Kuwahara filter后再合并在一起。因为对于图像的一个窗口，每个颜色通道中这一窗口对应的子区域的标准差与算术平均值都可能是不同的，比如说R通道中i=1对应的子区域具有最小的标准差，但B通道中i=2对应的子区域具有最小的标准差。因此正确的处理方式应当是，首先将待处理图像转换为HSV图像，再对纯度通道（Value）使用Kuwahara filter。这样就保证了对于一个窗口只有一个确定的子区域能够决定中心像素的值。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;缺陷&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;Kuwahara filter没有指出同时有多个子区域具有最小标准差的情况的处理方式。一般来说由于噪音的存在，两个区域具有完全相同标准差的情况是非常罕见的。当两区域具有相近标准差值时，中心像素的值基本上就是由噪声随机决定的（标准差值相近但算术平均值差别非常大），这也就让Kuwahara filter具有了对噪声敏感的缺陷。一种解决方法是取中心像素值为$ \frac{m_1+m_2}{2} $，$ m_1 $与$ m_2 $所对应的子区域之间标准差之差小于某特定值$ D $。&lt;/li&gt;
      &lt;li&gt;Kuwahara filter容易生成块状的不自然效果（block artifacts），这一现象在纹理丰富的区域尤为明显。其出现是因为窗口的区域划分是方形的，所以一种解决方式是取非矩形（如圆形）的窗口，另一种方法则是根据输入图像来生成特定的窗口。&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>Jingwen Huang</name></author><category term="Basics" /><summary type="html">​ Kuwahara filter是一种非线性的平滑滤波器。其主要特点是能够在保持边缘的前提下对图像进行平滑处理。</summary></entry></feed>